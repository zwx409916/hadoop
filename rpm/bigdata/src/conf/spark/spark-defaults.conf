spark.speculation.interval = 100
spark.acls.enable = false
spark.random.port.min = 23000
spark.speculation = false
spark.shuffle.memoryFraction = 0.2
spark.io.compression.lz4.blocksize = 32768
soark.executor.memory = 512m
spark.scheduler.revive.interval = 1000
spark.shuffle.manager = SORT
spark.shuffle.sort.bypassMergeThreshold = 200
spark.hadoop.validateOutputSpecs = true
spark.akka.frameSize = 10
spark.ui.port = 23000
spark.kryoserializer.buffer.max = 128m
spark.speculation.quantile = 0.75
spark.keyoserializer.buffer = 64k
spark.speculation.multiplier = 1.5
spark.eventLog.compress = false
spark.eventLog.overwrite = true
spark.ui.threadDumpsEnabled = false
spark.scheduler.minRegisteredResourcesRatio = 0.8
spark.storage.memoryFraction = 0.6
spark.files.overwrite = false
spark.shuffle.consolidateFiles = false
spark.random.port.max = 23999
spark.akka.timeout = 600
spark.eventLog.dir = hdfs://hacluster//sparkJobHistory
spark.locality.wait.process = 3000
spark.storage.unrollFraction = 0.2
spark.ui.killEnabled = false
spark.io.compression.codec = snappy
spark.scheduler.mode = FIFO
spark.shuffle.file.buffer = 32k
spark.broadcast.factory = org.apache.spark.broadcast.TorrentBroadcastFactory
spark.shuffle.compress = true
spark.locality.wait = 3000
spark.locality.wait.node = 3000
#
#
spark.broadcast.blocksize = 4096
spark.shuffle.spill = true
spark.storage.memoryMapThreshold = 8192
spark.serializer.objectStreamReset = 100
spark.kryo.referenceTracking  = true
spark.reducer.maxSizeInFlight =48
spark.eventLog.enabled = true
spark.io.compression.snappy.blocksize = 32768
spark.logConf = false
spark.executor.extraLibraryPath = @SNAPPY_LIB_PATH@
spark.files.fetchTimeout = 60
spark.kryo.registrationRequired = false
spark.port.maxRetyies = 16
spark.serializer = org.apache.spark.serializer.JavaSerializer
spark.ui.retainedStages =1000
spark.locality.wait.rack = 3000
spark.executor.heartbeatInterval = 10000
spark.localExecution.enabled = false
spark.rdd.compress = false
spark.task.maxFailures = 4
spark.akka.heartbeat.pauses = 6000
spark.akks.threads = 4
spark.scheduler.maxRegisteredResourcesWaitingTime = 30000
spark.shuffle.spill.compress = true
spark.task.cpus = 1
spark.yarn.jar = local:@YARN_JAR_PATH@
spark.local.dir = /tmp
spark.executor.extraJavaOptions = -Dlog4j.configuration=file:@SPARK_LOG_CONF_PATH@/log4j.properties -XX:compressedClassSpaceSize=512m
spark.driver.extraJavaOptions = -Djetty.version=x.y.z -XX:compressedClassSpaceSize=512m
spark.yarn.am.extraJavaOptions = -Dlog4j.configuration=file:@SPARK_LOG_CONF_PATH@/log4j.properties -XX:compressedClassSpaceSize=512m
spark.yarn.cluster.driver.extraLibraryPath = @SPARK_CLASSPATH@
spark.driver.extraClassPath = @SPARK_CLASSPATH@
spark.executor.extraClassPath = @SPARK_CLASSPATH@

spark.sql.bigdata.register.dialect=org.apache.spark.sql.hbase.HBaseSQLParser
spark.sql.bigdata.register.extendedResolutionRule=org.apache.spark.sql.hbase.catalyst.analysis.ReplaceOutput$
spark.sql.bigdata.register.strategyRule=org.apache.spark.sql.hbase.DummySparkPlanner
spark.sql.bigdata.register.preExecutionRule=org.apache.spark.sql.hbase.execution.AddCoprocessor$,org.apache.spark.sql.execution.EnsureRowFormat$
spark.sql.bigdata.initFunction=org.apache.spark.sql.hbase.HBaseEnv
spark.sql.bigdata.register.strategy.useFunction=true
spark.sql.hbase.userCheckDir=false
